# Python Scripts

All python scripts are located in `scripts/Python/`

Below I list the python scripts and the classes within them roughly in the context of a workflow,  Data required by the workflows as input is located in the `data_input/` directory and includes the following files,

	1. `master_peak_matrix.txt` : the input binary peak/OCR matrix.  Rows correspond to peaks/OCR and columns to cell types.  I hand downloaded this file from an S3 bucket.  It is the end output of the Yoshida-GEO-ATACseq-workflow.  The S3 url:  `s3://yoshida-atacseq/master/master_peak_matrix.txt`.
	2. `master_peak_table.bed` : bed file giving the genome position of each OCR.  The S3 url:  `s3://yoshida-atacseq/master/master_peak_table.bed`.
	3. `Yoshida_edge_list.csv` : a DataFrame containing the edges of the graph defined in Yoshida et al, Figure 1A.  I constructed this file by hand.
	4. `Yoshida_raw_download.csv`:  the annotated OCR results from the Yoshida et al paper.  I downloaded this file from https://sharehost.hms.harvard.edu/immgen/ImmGenATAC18_AllOCRsInfo.csv.
	5. `mouse_pwms_v2.rda`:  R object containing a list of motifs.  This is used as the base set of motifs in Yoshida et al.  Downloaded from `https://github.com/buenrostrolab/chromVARmotifs`.  

The main input to the workflow is a binary matrix (`master_peak_matrix.txt`) with rows corresponding to genomic loci and columns to cell types (or some other factor) and a file containing edges for the graph describing the relationship of columns in the binary matrix (`Yoshida_edge_list.csv`).  The other files are not used in the clustering algorithm.

## Configuration: `configuration.py`

The script 'configuration.py' contains the following global variables accessed by the other python scripts.  

* `DATA_DIR` : relative path to the directory used to store and access data generated by the analysis, currents `data_output/`.  The different scripts create and access different subdirectories within `$DATA_DIR`.
* `INPUT_DATA` : the directory containing pre-existing datasets, curretnly `data_input/`.  
* `BEDTOOLS_PATH`:  path to the bedtools executable.  This is only relevant for some methods in some classes, set it to an empty string if not needed.


## Defining the binary matrix: `master_peaks.py`

### master peaks class

The class `master_peaks` provides access to the master peaks files in the `$INPUT_DATA` directory (see above).

Accessory methods: 

* `load_matrix()` : loads `master_peak_matrix.txt`
* `load_table()` : loads `master_peak_table.bed`
* `load_sequences()` : loads the nucleotide sequences (500 bp) associated with each OCR.
* `get_cell_types()` : provides the cell types corresponding to the columns of the binary, OCR matrix.

# Yoshida data and tree:   `Yoshida.py`

This script provides access to data and the tree found in the Yoshida et al paper.  Yoshida et al (2019) *The cis-Regulatory Atlas of the Mouse Immune System*. Cell.

### Yoshida data class

The class `Yoshida_data` provides access to the OCR data matrix constructed in Yoshida et al.  
Accessor methods:

* `load_matrix()`:  loads the OCR matrix defined by Yoshida
* `load_bed() : loads bed file with OCR genomic locations
* 'load_raw_data()': loads the Yoshida csv file which contains the OCR matrix with addtional fields.

### Yoshida tree class

The class `Yoshida_tree` defines an igraph object representing the tree in Yoshida Figure 1A.  
Accessor methods:

* `load_igraph(just_root)`:   Returns the igraph object for the Yoshida tree.  If `just_root' is True, then cell types not in the HSC tree, for which LTHSC.34-.BM is the root, are not included.  This is the default!
* 'load_edgelist()':  returns the edge list defining the Yoshida tree.

## Clustering rows:  `peak_clusters.py`

### create peak clusters class

This class clusters the rows (i.e. ATACseq peaks or OCR) of the binary OCR matrix.  More specifically, it applies a Louvain clustering algorithm to the rows after defining edges between rows based on a null model defining when two rows are significantly similar.

Constructing this class applies the Louvain clustering and creates two files in `$DATA_DIR/peak_clusters`.

* `edge_list.csv`:  A list of edges between rows that is used as the input to the Louvain algorithm
* `clusters.csv`:  A DataFrame with columns `row` and `cluster` that provide the row index and its cluster, respectively.

**Note**:  Not all rows are assigned to a cluster.  Instead, only rows that are associated with an edge are assigned.  

### peak clusters class

This class provides an interface into the clustering computed by the create peak clusters class.

Accessor methods:

* `load_clusters()`:  loads the cluster DataFrame created by create peak clusters
* `get_cluster_sizes(min_cluster_size=50)`:  returns a DataFrame containing the cluster number and number of rows in the cluster. Note that `min_cluster_size` just determines which clusters are returned, not the actual clustering done.
* `get_cluster_bed(index)`:  returns a bed file specifying the location of peaks/OCR for the rows in a particular cluster.
* `form_cluster_matrix(index)`:  returns the OCR binary matrix with rows restricted to the particular cluster.
* `form_cluster_sequences(index)`:  returns the sequences of the OCR corresponding to the rows in a particular cluster.

### null peak clusters

This class is a computational class used by create peak clusters to determine the edge list inputted to the Louvain algorithm.   It needs to be constructed once prior to a call to create peak clusters.

## Clustering columns: `tree_cluster.py`

The class tree cluster is constructed using a igraph object (assumed to be a tree), a list of matrices with the number of columns in each matrix equal and corresponding in order to the igraph vertices, and the number of clusters, K.

Methods:

* `initialize_components()`:  initializes the clusters/components
* `get_assignments()`: the cluster assignment for each vertex
* `get_mediods()`:  the medios of each cluster for each of the matrices passed to the constructor
* `optimize()`:  runs a coordiante descent to find optimum clustering given a starting point/assignment
* `fit(num_runs)`:  runs `num_runs` optimizations with different random starting points in order to find global min/global optimal clustering.
* `treeplot(m_index=None)`:  shows the clustering as an igraph plot with vertices color coded.   `m_index` can be used to choose a matrix from the constructor, in which case the vertex sizes are the fraction of 1's in the columns.
* `boxplot(num_m_index)`:  produces a box plot with x-axis giving the cluster and y-axis showing the frequency of 1's over the columns in the cluster.  Faceting is used to show a box plot for each of the first `num_m_index` matrices.
* `heatmap(num_m_index)`: a heat map showing the cluster means across the different vertices.

## mm10 genome annotations:  `mm10.py`

### mm10 biomart class

Downloads biomart annotations for mm10 transcripts.

Methods:
* `load()`: dataframe with annotations
* `to_bed(outfile, padding)`:  creates a bed file of the genomic locus of the TSS for each transcript in the dataframe returned by `load()`.  `padding` adds base pairs to the left and right of the TSS in the bed file.

### mm10 genome

Requires a path to an **indexed** mm10 fasta file, specified in `configuration.py`.  

Methods:
* `sequences(bed_file)`:  returns the nucleotide sequences on mm10 for genomic loci specified by a bed file.

# Still in progress...

## Clustering the Yoshida dataset: `Yoshida_cluster.py`

This class is still a work in progress.  It combines the row and column clustering on the binary peak/OCR matrix.  The goal of the class is to compute clusterings for different K values and assess the corresponding fits to the data.

